import os
import json
import logging
import re
from typing import Any, Dict, Optional

# KÃ¼tÃ¼phane ve modÃ¼l importlarÄ± burada kalmalÄ±
try:
    import google.generativeai as genai
except ImportError as e:
    raise ImportError(
        "google-generativeai is not installed. Install with:\n"
        "pip install google-generativeai"
    ) from e

from app.assessment_engine import AssessmentEngine
from app.scenario_manager import ScenarioManager
from app.mock_responses import get_mock_interpretation
from app.services.med_gemma_service import MedGemmaService
from app.services.rule_service import rule_service


logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


DENTAL_EDUCATOR_PROMPT = """
You are a dental education assistant helping to interpret student actions within a simulated clinical scenario.
Your job is to:
1) Classify if the input is CHAT (casual conversation) or ACTION (clinical action).
2) Interpret the student's raw action text into a normalized action key that can be scored by a rule engine.
3) Identify the clinical intent category.
4) Flag any safety concerns if present.
5) Provide a short, neutral, and professional explanation for the student (1-3 sentences max).
6) Output STRICT JSON ONLY, without additional commentary or code fences.
7) Respect the language policy: INTERNAL LOGIC (keys) must be in English (e.g., 'check_allergies'), while EXTERNAL RESPONSE (explanatory_feedback) must be in TURKISH.

CRITICAL OUTPUT REQUIREMENTS:
- Respond with ONLY a JSON object. No markdown, no code blocks, no prose.
- The JSON schema must be:
{
  "intent_type": "string: 'CHAT' | 'ACTION'. Use CHAT for greetings/questions, ACTION for clinical steps.",
  "interpreted_action": "string: normalized action key, snake_case (e.g., 'check_allergy_history')",
  "clinical_intent": "string: e.g., 'history_taking' | 'diagnosis_gathering' | 'treatment_planning' | 'patient_education' | 'infection_control' | 'radiography' | 'anesthesia' | 'restorative' | 'periodontics' | 'endodontics' | 'oral_surgery' | 'prosthodontics' | 'orthodontics' | 'follow_up' | 'other'",
  "priority": "string: 'high' | 'medium' | 'low'",
  "safety_concerns": ["array of strings; empty if none"],
  "explanatory_feedback": "string: concise explanation for the learner (<= 3 sentences).",
  "structured_args": { "optional object with any arguments relevant to the action" }
}

Guidance:
- **USE ONLY THE FOLLOWING ACTION KEYS:** ['gather_medical_history', 'gather_personal_info', 'check_allergies_meds', 'order_radiograph', 'diagnose_pulpitis', 'prescribe_antibiotics', 'refer_oral_surgery', 'check_pacemaker', 'check_bleeding_disorder', 'check_diabetes', 'check_oral_hygiene_habits', 'check_vital_signs', 'prescribe_palliative_care', 'ask_systemic_symptoms', 'perform_pathergy_test', 'request_serology_tests', 'perform_oral_exam', 'perform_extraoral_exam', 'perform_nikolsky_test', 'request_dif_biopsy', 'diagnose_herpetic_gingivostomatitis', 'diagnose_behcet_disease', 'diagnose_secondary_syphilis', 'diagnose_mucous_membrane_pemphigoid']. If none fit, use 'unspecified_action'.
- If the student's action is unclear or unsafe, set "priority" accordingly and add a safety note in "safety_concerns".
- Prefer conservative, safety-first interpretations.
- Use the provided scenario state context to disambiguate intent when possible.
"""

# Bu fonksiyon, LLM'in gÃ¶nderdiÄŸi gereksiz metni temizleyerek JSON'a ulaÅŸmaya Ã§alÄ±ÅŸÄ±r.
def _extract_first_json_block(text: str) -> Optional[str]:
    # ... (Buraya daha Ã¶nce verdiÄŸin _extract_first_json_block fonksiyonunun tamamÄ± gelecek) ...
    # Bu fonksiyon doÄŸru Ã§alÄ±ÅŸtÄ±ÄŸÄ± varsayÄ±lÄ±yor.
    # ...
    text = text.strip()

    # 1) Try direct parse
    try:
        json.loads(text)
        return text
    except Exception:
        pass

    # 2) Try fenced blocks ```json ... ``` or ``` ... ```
    fence_patterns = [
        r"```json\s*(\{.*?\})\s*```",
        r"```\s*(\{.*?\})\s*```",
    ]
    for pat in fence_patterns:
        m = re.search(pat, text, flags=re.DOTALL)
        if m:
            candidate = m.group(1).strip()
            try:
                json.loads(candidate)
                return candidate
            except Exception:
                continue

    # 3) Fallback: greedy first {...}
    m = re.search(r"(\{.*\})", text, flags=re.DOTALL)
    if m:
        candidate = m.group(1).strip()
        try:
            # En son { veya } karakterine kadar olan kÄ±smÄ± kesebilirsin
            # Bu, basit bir regexp yaklaÅŸÄ±mÄ±dÄ±r
            return candidate
        except Exception:
            return None

    return None

class DentalEducationAgent:
    """
    Orchestrator agent for the hybrid AI workflow:
    - Uses Gemini to interpret the student's raw text action into structured JSON.
    - Uses AssessmentEngine for objective scoring against rules.
    - Combines interpretation + scoring into final feedback.
    - Updates the scenario state via ScenarioManager.
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        model_name: str = "models/gemini-2.5-flash-lite",  # VarsayÄ±lan: lite model (dÃ¼ÅŸÃ¼k maliyet)
        temperature: float = 0.2,
        assessment_engine: Optional[AssessmentEngine] = None,
        scenario_manager: Optional[ScenarioManager] = None,
    ) -> None:
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError(
                "GEMINI_API_KEY not set. Provide api_key param or set environment variable GEMINI_API_KEY."
            )

        genai.configure(api_key=self.api_key)

        self.model = genai.GenerativeModel(
            model_name=model_name,
            system_instruction=DENTAL_EDUCATOR_PROMPT,
            generation_config={
                "temperature": temperature,
                "top_p": 0.9,
                "top_k": 40,
                "max_output_tokens": 512,
                # Hint to return JSON. Some SDK versions honor this directly.
                "response_mime_type": "application/json",
            },
        )

        self.assessment_engine = assessment_engine or AssessmentEngine()
        self.scenario_manager = scenario_manager or ScenarioManager()
        
        # MedGemma: Silent Grader (Arka planda Ã§alÄ±ÅŸÄ±r)
        try:
            self.med_gemma = MedGemmaService()
            logger.info("MedGemma servis baÅŸarÄ±yla baÅŸlatÄ±ldÄ± (Silent Evaluator)")
        except Exception as e:
            logger.warning(f"MedGemma baÅŸlatÄ±lamadÄ±: {e}. Sessiz deÄŸerlendirme olmadan devam edilecek.")
            self.med_gemma = None

    def interpret_action(self, action: str, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Use Gemini (Single Call) to convert raw action into structured JSON.
        """
        context_snippet = {
            "case_id": state.get("case_id"),
            "patient_age": state.get("patient", {}).get("age"),
            "chief_complaint": state.get("patient", {}).get("chief_complaint"),
            "revealed_findings": state.get("revealed_findings"),
        }

        user_prompt = (
            "Student action:\n"
            f"{action}\n\n"
            "Scenario state (partial):\n"
            f"{json.dumps(context_snippet, ensure_ascii=False)}\n\n"
            "Return STRICT JSON ONLY following the required schema."
        )

        try:
            response = self.model.generate_content(user_prompt)
            raw_text = getattr(response, "text", "") or ""
            json_str = _extract_first_json_block(raw_text)

            if not json_str:
                # EÄŸer JSON yoksa, ama metin varsa, bunu CHAT olarak kabul et (Fallback)
                if raw_text and len(raw_text) < 200:
                    return {
                        "intent_type": "CHAT",
                        "interpreted_action": "general_chat",
                        "explanatory_feedback": raw_text.strip(),
                        "clinical_intent": "other",
                        "priority": "low",
                        "safety_concerns": [],
                        "structured_args": {},
                    }
                raise ValueError("Failed to extract JSON from model response.")

            data = json.loads(json_str)

            # Normalize data
            interpreted = {
                "intent_type": data.get("intent_type", "ACTION").strip(),
                "interpreted_action": data.get("interpreted_action", "").strip(),
                "clinical_intent": data.get("clinical_intent", "other").strip() or "other",
                "priority": data.get("priority", "medium").strip() or "medium",
                "safety_concerns": data.get("safety_concerns", []) or [],
                "explanatory_feedback": data.get("explanatory_feedback", "").strip(),
                "structured_args": data.get("structured_args", {}) or {},
            }
            return interpreted

        except Exception as e:
            logger.exception(f"LLM interpretation failed: {e}")
            
            # KullanÄ±cÄ± dostu hata mesajÄ± ve kota aÅŸÄ±mÄ±nda mock yanÄ±t
            error_msg = str(e)
            if "quota" in error_msg.lower() or "429" in error_msg:
                logger.warning("API quota exceeded. Using mock interpretation fallback.")
                # KOTA AÅIMI: Mock sistem ile devam et
                try:
                    mock_result = get_mock_interpretation(action)
                    mock_result["explanatory_feedback"] = "âš ï¸ API kotasÄ± doldu (Mock sistem aktif). " + mock_result["explanatory_feedback"]
                    return mock_result
                except Exception as mock_err:
                    logger.error(f"Mock interpretation failed: {mock_err}")
                    feedback = "â³ API gÃ¼nlÃ¼k kullanÄ±m limiti doldu. LÃ¼tfen yarÄ±n tekrar deneyin."
            else:
                feedback = "AnlaÅŸÄ±lamadÄ± (Teknik Hata). LÃ¼tfen tekrar dener misiniz?"
            
            # HATA DURUMUNDA 'CHAT' OLARAK DÃ–N (PUANI GÄ°ZLEMEK Ä°Ã‡Ä°N)
            return {
                "intent_type": "CHAT",
                "interpreted_action": "error",
                "explanatory_feedback": feedback,
                "safety_concerns": [],
                "clinical_intent": "other",
                "priority": "low",
                "structured_args": {},
            }

    def _silent_evaluation(
        self, 
        student_input: str, 
        interpreted_action: str, 
        state: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        MedGemma sessizce arka planda deÄŸerlendirme yapar.
        Bu fonksiyon konuÅŸma akÄ±ÅŸÄ±nÄ± ENGELLEMEZ.
        DeÄŸerlendirme baÅŸarÄ±sÄ±z olursa boÅŸ dict dÃ¶ner.
        """
        if not self.med_gemma:
            logger.debug("MedGemma mevcut deÄŸil, sessiz deÄŸerlendirme atlanÄ±yor")
            return {}

        try:
            case_id = state.get("case_id", "default_case")
            category = state.get("category", "GENERAL")
            
            # Kategori iÃ§in aktif kurallarÄ± al
            rules = rule_service.get_active_rules(category)
            
            # Hasta baÄŸlamÄ± Ã¶zeti oluÅŸtur
            patient = state.get("patient", {})
            context_summary = (
                f"Hasta: {patient.get('age', 'Bilinmiyor')} yaÅŸÄ±nda. "
                f"Åikayet: {patient.get('chief_complaint', 'BelirtilmemiÅŸ')}. "
                f"Bulgular: {', '.join(state.get('revealed_findings', []))}"
            )
            
            # MedGemma'yÄ± Ã§aÄŸÄ±r (sessiz deÄŸerlendirme)
            logger.info(f"[Sessiz DeÄŸerlendirme] BaÅŸlatÄ±lÄ±yor: {interpreted_action}")
            evaluation = self.med_gemma.validate_clinical_action(
                student_text=student_input,
                rules=rules,
                context_summary=context_summary
            )
            
            logger.info(f"[Sessiz DeÄŸerlendirme] TamamlandÄ±: {evaluation.get('is_clinically_accurate', 'Bilinmiyor')}")
            return evaluation
            
        except Exception as e:
            logger.warning(f"Sessiz deÄŸerlendirme baÅŸarÄ±sÄ±z (kritik deÄŸil): {e}")
            return {}

    def _compose_final_feedback(
        self, 
        interpretation: Dict[str, Any], 
        assessment: Dict[str, Any]
    ) -> str:
        """
        Gemini yorumu ve kural motoru puanÄ±ndan final geri bildirim oluÅŸturur.
        Ã–ÄŸrenciye gÃ¶sterilecek olan metni dÃ¶ner.
        """
        # Gemini'nin aÃ§Ä±klayÄ±cÄ± geri bildirimi Ã¶nceliklidir
        explanatory = interpretation.get("explanatory_feedback", "")
        
        # EÄŸer CHAT tipindeyse, sadece aÃ§Ä±klayÄ±cÄ± geri bildirimi dÃ¶ndÃ¼r
        if interpretation.get("intent_type") == "CHAT":
            return explanatory
        
        # ACTION tipindeyse, puan bilgisini de ekleyebiliriz (opsiyonel)
        # Ama Silent Evaluator mimarisinde, UI'da puan gÃ¶stermiyoruz
        # Bu yÃ¼zden sadece aÃ§Ä±klayÄ±cÄ± metni dÃ¶nÃ¼yoruz
        return explanatory

    def process_student_input(self, student_id: str, raw_action: str, case_id: Optional[str] = None) -> Dict[str, Any]:
        """
        Silent Evaluator Architecture ile Hibrit Pipeline:
        
        1) Gemini: Ã–ÄŸrenci eylemini yorumlar (EÄŸitim AsistanÄ± rolÃ¼nde)
        2) AssessmentEngine: Kural bazlÄ± puanlama yapar
        3) MedGemma: ARKA PLANDA sessizce deÄŸerlendirir (konuÅŸmayÄ± engellemez)
        4) Final feedback oluÅŸturulur ve tÃ¼m sonuÃ§lar dÃ¶ner
        
        Args:
            student_id: Ã–ÄŸrenci kimliÄŸi
            raw_action: Ã–ÄŸrencinin ham giriÅŸi
            case_id: Aktif vaka kimliÄŸi (opsiyonel, state'den alÄ±nabilir)
        
        Returns:
        {
          "student_id": str,
          "case_id": str,
          "llm_interpretation": dict (Gemini yorumu - response_text iÃ§erir),
          "assessment": dict (Kural motoru puanÄ±),
          "silent_evaluation": dict (MedGemma arka plan deÄŸerlendirmesi),
          "final_feedback": str (Ã–ÄŸrenciye gÃ¶sterilen geri bildirim),
          "updated_state": dict
        }
        """
        # Step 1: Get Context (persistent)
        # If case_id is provided, bind to that session/case so state is stored correctly.
        state = self.scenario_manager.get_state(student_id, case_id=case_id) if case_id else self.scenario_manager.get_state(student_id)
        state = state or {}

        # Use provided case_id or fallback to state
        if not case_id:
            case_id = state.get("case_id", "default_case")
        else:
            state["case_id"] = case_id

        # Step 2: Gemini Interpretation (EÄŸitim AsistanÄ±)
        interpretation = self.interpret_action(raw_action, state)
        interpreted_action = interpretation.get("interpreted_action", "")

        # Step 3: Objective Scoring (Kural Motoru)
        assessment = self.assessment_engine.evaluate_action(case_id, interpretation) or {}

        # Step 4: Silent Evaluation (MedGemma - Arka Plan)
        # Bu Ã§aÄŸrÄ± BAÅARISIZ olsa bile diÄŸer iÅŸlemler devam eder
        silent_evaluation = self._silent_evaluation(raw_action, interpreted_action, state)

        # Step 5: Final Feedback (Gemini + Puanlama)
        final_feedback = self._compose_final_feedback(interpretation, assessment)

        # Step 6: Update State
        # Always propagate score_change (even when a rule has no state_updates).
        score_delta = assessment.get("score_change")
        state_updates = (
            assessment.get("state_updates")
            or assessment.get("state_update")
            or assessment.get("new_state_data")
            or {}
        )
        combined_updates: Dict[str, Any] = {}
        if isinstance(score_delta, (int, float)) and score_delta:
            combined_updates["score_change"] = score_delta
        if isinstance(state_updates, dict) and state_updates:
            combined_updates.update(state_updates)

        if combined_updates:
            try:
                self.scenario_manager.update_state(student_id, combined_updates, case_id=case_id)
            except Exception as e:
                logger.exception("Failed to update scenario state: %s", e)

        updated_state = self.scenario_manager.get_state(student_id, case_id=case_id) or state

        return {
            "student_id": student_id,
            "case_id": case_id,
            "llm_interpretation": interpretation,  # iÃ§inde 'explanatory_feedback' var (response_text gibi)
            "assessment": assessment,
            "silent_evaluation": silent_evaluation,  # YENI: MedGemma deÄŸerlendirmesi
            "final_feedback": final_feedback,
            "updated_state": updated_state,
        }


if __name__ == "__main__":
    """
    Test: Silent Evaluator Architecture
    Gemini = EÄŸitim AsistanÄ± | MedGemma = Sessiz DeÄŸerlendirici
    """
    from dotenv import load_dotenv
    load_dotenv()
    
    try:
        print("=" * 60)
        print("SESSIZ DEÄERLENDÄ°RÄ°CÄ° MÄ°MARÄ°SÄ° TEST")
        print("=" * 60)
        
        agent = DentalEducationAgent()
        
        test_student_id = "test_student_001"
        test_action = "HastanÄ±n alerji geÃ§miÅŸini ve kullandÄ±ÄŸÄ± ilaÃ§larÄ± sorguluyorum."
        
        print(f"\nğŸ‘¤ [Ã–ÄŸrenci ID]: {test_student_id}")
        print(f"ğŸ’¬ [Ã–ÄŸrenci Girdisi]: {test_action}")
        print("\n" + "-" * 60)
        
        # Silent Evaluator ile iÅŸle (test iÃ§in olp_001 vakasÄ±)
        result = agent.process_student_input(test_student_id, test_action, case_id="olp_001")
        
        print("\nğŸ“ GEMINI YORUMU (EÄŸitim AsistanÄ±):")
        print(f"   {result['llm_interpretation'].get('explanatory_feedback', 'Yok')}")
        
        print(f"\nğŸ” Yorumlanan Eylem:")
        print(f"   {result['llm_interpretation'].get('interpreted_action', 'Yok')}")
        
        print("\nğŸ“Š KURAL MOTORU PUANI:")
        print(f"   Puan: {result['assessment'].get('score', 'N/A')}")
        print(f"   SonuÃ§: {result['assessment'].get('rule_outcome', 'N/A')}")
        
        print("\nğŸ”¬ MEDGEMMA SESSIZ DEÄERLENDÄ°RME (Arka Plan):")
        silent_eval = result.get('silent_evaluation', {})
        if silent_eval:
            print(f"   âœ“ Klinik DoÄŸruluk: {silent_eval.get('is_clinically_accurate', 'N/A')}")
            print(f"   âš ï¸  GÃ¼venlik Ä°hlali: {silent_eval.get('safety_violation', 'N/A')}")
            print(f"   ğŸ“ MedGemma Geri Bildirimi: {silent_eval.get('feedback', 'N/A')}")
            if silent_eval.get('missing_critical_info'):
                print(f"   âš¡ Eksik Bilgi: {silent_eval.get('missing_critical_info')}")
        else:
            print("   (MedGemma deÄŸerlendirmesi mevcut deÄŸil - servis baÅŸlatÄ±lamadÄ±)")
        
        print("\nğŸ“‹ Ã–ÄRENCÄ°YE GÃ–STERILEN FÄ°NAL GERÄ° BÄ°LDÄ°RÄ°M:")
        print(f"   {result['final_feedback']}")
        
        print("\n" + "=" * 60)
        print("TEST TAMAMLANDI âœ“")
        print("=" * 60)
        
    except ValueError as e:
        print(f"\nâŒ BAÅLATMA HATASI: {e}")
    except Exception as e:
        logger.exception("Test baÅŸarÄ±sÄ±z")
        print(f"\nâŒ Ã‡ALIÅMA ZAMANI HATASI: {e}")